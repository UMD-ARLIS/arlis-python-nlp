{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIIDStuff.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **arlis-python-nlp**\n",
        "Natural Language Processing Libraries for Text Extraction and Indexing specifically designed for the articles in the [Artificial Intelligence Incident Database](https://incidentdatabase.ai/) (AIID)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Introduction**\n",
        "This GitHub repository is for those who are involved in filling out the requried [taxonomy fields](https://incidentdatabase.ai/taxonomy/cset) for the  articles in AIID. Many of the taxonomy fields as of writing this documentation have been filled manually, our program focuses on automating this process. The taxonomy fields that our program automates is Full description of the incident, Sector of deployment, Location, and Named Entities. If our work continues in the future, we will focus on trying to automate even more taxonomy fields. The way our program works is that you would import our libraries and use our functions to get these taxonomy fields. This is will be further explained in the following section.\n",
        "\n",
        "### **Usage** \n",
        "This section will explain how to use our program to extract taxonomy fields for an article using our example program, [example.py](https://github.com/UMD-ARLIS/arlis-python-nlp/blob/main/example.py).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Before using our program**\n",
        "Our program uses our own library (arlis-python-nlp) as well as NLTK. Arlis-python-nlp and NLTK would have to be installed and imported for our program to run. Down below our two blocks that show how to install/import the required libraries. (Note: this does not include information on how to install NLTK). The first block with five lines of code is what you would run on your terminal (without <font color='red'>!</font>)"
      ],
      "metadata": {
        "id": "Pw0XBGjVFXp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIbD3l2-My6Q"
      },
      "outputs": [],
      "source": [
        "#https://huggingface.co/joeddav/xlm-roberta-large-xnli?text=Can+you+please+amend+the+invoice+to+reflect+true+capital+expenditure+and+anticipated+revenue%3F&candidate_labels=Medical%2Cbusiness%2Cfinance&multi_class=true\n",
        "\n",
        "# CUDA 11.1\n",
        "# Site to visit for later version: https://pytorch.org/get-started/previous-versions/\n",
        "!pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install newspaper3k\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing proper packages onto your machine, the following functions will need to be imported and defined as follow:"
      ],
      "metadata": {
        "id": "_LC5exAHMdEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "from newspaper import Article\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\")\n",
        "\n",
        "#Location Finder\n",
        "def locationFinder(text):\n",
        "    gpe = [] # countries, cities, states\n",
        "    loc = [] # non gpe locations, mountain ranges, bodies of water\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "      if (ent.label_ == 'GPE'):\n",
        "        gpe.append(ent.text)\n",
        "      elif (ent.label_ == 'LOC'):\n",
        "        loc.append(ent.text)\n",
        "    return gpe, loc\n",
        "\n",
        "#Extraction people and organizations involved\n",
        "def nameEntityFinder(paragraph):\n",
        "    doc = nlp(paragraph)\n",
        "    nameEntityDict = {}\n",
        "    nameEntityDict_v2 = {}\n",
        "    for ent in doc.ents:\n",
        "      nameEntityDict[ent.text] = ent.label_\n",
        "      \n",
        "    for (key, value) in nameEntityDict.items():\n",
        "        if value == 'PERSON' or value == 'ORG':\n",
        "            nameEntityDict_v2[key] = value\n",
        "    return nameEntityDict_v2\n",
        "\n",
        "#Returns sector of deployment\n",
        "def get_Sector_of_Deployment(text):\n",
        "  sectorDeployment = ['Information and communication', 'Arts, entertainment and recreation', 'Transportation and storage', 'Public administration and defence', 'Administrative and support service activities', 'Human health and social work activities', 'Education', 'Professional, scientific and technical activities', 'Financial and insurance activities', 'Wholesale and retail trade', 'Activities of households as employers', 'Accommodation and food service activities']\n",
        "  vector = classifier(text, sectorDeployment)\n",
        "  return vector['labels'][0]\n",
        "\n",
        "#Return sector of infrastructure\n",
        "def get_infrastructure_sector(text):\n",
        "  infrastructureSector = ['Transportation', 'Healthcare and public health', 'Government facilities', 'Communications', 'Food and agriculture', 'Critical manufacturing', 'Nuclear', 'Financial services', 'Information technology']\n",
        "  vector = classifier(text, infrastructureSector)\n",
        "  return vector['labels'][0]\n",
        "\n",
        "#Return harm type\n",
        "def get_harm_type(text):\n",
        "  harmType = ['Harm to social or political systems', 'Harm to civil liberties', 'Harm to physical health/safety', 'Psychological harm', 'Financial harm', 'Harm to physical property', 'Harm to intangible property', 'Other:Harm to publicly available information', 'Other:Reputational harm; False incarceration', 'Other:Reputational harm', 'Other:Privacy', 'Other', 'Other:Reputational harm/social harm (libel and defamation)']\n",
        "  vector = classifier(text, harmType)\n",
        "  return vector['labels'][0]\n",
        "\n",
        "#Returns pandas dataframe of all functions\n",
        "def totalFunctions(url):\n",
        "  article = Article(url)\n",
        "  article.download()\n",
        "\n",
        "  article.parse() #parses through the text\n",
        "  article.nlp() \n",
        "  article.keywords\n",
        "  df = pd.DataFrame()\n",
        "  df['Function']=['Keywords', 'Author', 'Article Summary', 'Harm Type', 'Sector of Deployment', 'Sector of Infrastructure', 'Named Entities']\n",
        "  df['Result']=[article.keywords, article.authors, article.summary, get_harm_type(article.text), get_Sector_of_Deployment(article.text), get_infrastructure_sector(article.text), nameEntityFinder(article.text)]\n",
        "  return df"
      ],
      "metadata": {
        "id": "LfSEEZA2HARR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a85cce8-be2e-4415-b3bf-34fcc9cc10a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Creating Article Summary Object**\n",
        "### This will be specific to the URL or link you want to use\n",
        "To enter the website link into the code, the way it is done is through creating a article summary object. In the code block down below, the Article object is article and inside the paranthesis of Article is where you would enter your article link. The article should be downloaded, parsed, and go through the nlp function shown below. There is no output for these commands but these lines of code are vital to use the functions below. "
      ],
      "metadata": {
        "id": "-aDMlPujF3Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = Article('https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()"
      ],
      "metadata": {
        "id": "x2yGeSpwOmK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **How to use the functions**\n",
        "There are a total of eight useful functions that can retrieve infromation from an article. These include extraction of keywords, full description of the article, retrieving the article's authors, identifying the named entities in the article, getting the sector of deployment and sector of infrastructure, and harm type. The last function can pull all information together and return the output in a dataframe. Here, we use a [2015 article from The Guardian](https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study) to show how our functions work.\n",
        "\n",
        "Here is how to extract key words from an article:"
      ],
      "metadata": {
        "id": "DvvYf7yvGDpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article.keywords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHhGE2dTJr6O",
        "outputId": "e16eef50-6a13-4b35-ddfe-f9e4d8b7e52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['likely',\n",
              " 'jobs',\n",
              " 'highpaid',\n",
              " 'abuse',\n",
              " 'substance',\n",
              " 'google',\n",
              " 'users',\n",
              " 'group',\n",
              " 'ad',\n",
              " 'sites',\n",
              " 'shown',\n",
              " 'shows',\n",
              " 'adverts',\n",
              " 'ads',\n",
              " 'researchers',\n",
              " 'study',\n",
              " 'women']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following line of code gives the user a summary or full description of the article:"
      ],
      "metadata": {
        "id": "kPLTgbNEONxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article.summary"
      ],
      "metadata": {
        "id": "xnzMYrLnH6Ju",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "46aa3f56-6a45-4e00-e6c3-4121aa5fd9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Female job seekers are much less likely to be shown adverts on Google for highly paid jobs than men, researchers have found.\\nTheir 17,370 fake profiles only visited jobseeker sites and were shown 600,000 adverts which the team tracked and analysed.\\nThe adverts shown to the control group did not include any rehabilitation services.\\nThe Watershed site was included in the top 100 substance abuse sites list, which was used as the experimental list of sites to visit by the automated system.\\nGoogle has said that it prohibits the targeting of adverts within its “sensitive category policy”, which includes health issues such as substance abuse.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function calls for the article's authors:"
      ],
      "metadata": {
        "id": "91Bf8MUNOXs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article.authors"
      ],
      "metadata": {
        "id": "3xo5-rMzKIQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37203caf-f5b9-4eed-b413-35f6664e06db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Samuel Gibbs']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function lists all the named entities: "
      ],
      "metadata": {
        "id": "44lTK504Ocbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nameEntityFinder(article.text)"
      ],
      "metadata": {
        "id": "SanghaCHKIFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7615636-e47f-454c-b292-2bd3b99ac057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AdFisher': 'PERSON',\n",
              " 'Carnegie Mellon': 'ORG',\n",
              " 'Google': 'ORG',\n",
              " 'Watershed': 'ORG'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function returns the primary economic sector in which the AI system(s) involved in the incident were operating."
      ],
      "metadata": {
        "id": "Zc_lyYVXO1gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_Sector_of_Deployment(article.text)"
      ],
      "metadata": {
        "id": "Bpo8INqdGDBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9cc6260-f1fa-41c1-8e9c-db8437937825"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Administrative and support service activities'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will return the field that indicates if the incident caused harm to any of the economic sectors designated by the U.S. government as critical infrastructure"
      ],
      "metadata": {
        "id": "D9f_-2gFO5o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_infrastructure_sector(article.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PChjKB7aYNia",
        "outputId": "82613e32-c31f-44b9-f5a5-ebdaefe28315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Information technology'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will indicate the type(s) of harm caused or nearly caused by the incident:"
      ],
      "metadata": {
        "id": "iuYmthFLO8_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_harm_type(article.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Pi-NmxEzZrxa",
        "outputId": "a43b0bf5-9f6b-44e7-e885-f985329a40a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Harm to physical property'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can combine all seven functions above into one function that returns all the outputs as a dataframe. The dataframe can then be exported as a csv or any other file time as needed."
      ],
      "metadata": {
        "id": "1kAMyC26PZbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "totalFunctions('https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "zXZnNMDTPk4U",
        "outputId": "f2d352e9-ca39-435f-c4da-4600b993b997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Function                                             Result\n",
              "0                  Keywords  [shows, women, shown, ad, adverts, users, abus...\n",
              "1                    Author                                     [Samuel Gibbs]\n",
              "2           Article Summary  Female job seekers are much less likely to be ...\n",
              "3                 Harm Type                          Harm to physical property\n",
              "4      Sector of Deployment      Administrative and support service activities\n",
              "5  Sector of Infrastructure                             Information technology\n",
              "6            Named Entities  {'Carnegie Mellon': 'ORG', 'AdFisher': 'PERSON..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17f97804-0916-4a95-8d4a-e952d996d918\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Function</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Keywords</td>\n",
              "      <td>[shows, women, shown, ad, adverts, users, abus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Author</td>\n",
              "      <td>[Samuel Gibbs]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Article Summary</td>\n",
              "      <td>Female job seekers are much less likely to be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Harm Type</td>\n",
              "      <td>Harm to physical property</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sector of Deployment</td>\n",
              "      <td>Administrative and support service activities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sector of Infrastructure</td>\n",
              "      <td>Information technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Named Entities</td>\n",
              "      <td>{'Carnegie Mellon': 'ORG', 'AdFisher': 'PERSON...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17f97804-0916-4a95-8d4a-e952d996d918')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17f97804-0916-4a95-8d4a-e952d996d918 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17f97804-0916-4a95-8d4a-e952d996d918');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save the above dataframe in a csv file, use the code below:"
      ],
      "metadata": {
        "id": "8J0JlUyIVg5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = totalFunctions('https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study')\n",
        "df.to_csv('ArticleSummaryDataFrame.csv', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "ksG4iPTDVfR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Conclusion** \n",
        "This library can extract key information however it is important to know that this process may not always be correct. Therefore if you are using this library for an important task, it is highly reccomended to check the results the code provides. Down below is a table that includes the names and contact information of the creators of this library. Please feel free to contact us using this contact information for any questions \n",
        "\n",
        "\n",
        "\n",
        "| Name | Email |\n",
        "| --- | --- |\n",
        "|Ujwal Gupta | ugupta12@umd.edu|\n",
        "|Marcus Hill | mhill128@umd.edu|\n",
        "|Ayushi Saxena | asaxena1@umd.edu|"
      ],
      "metadata": {
        "id": "KU5lsbpGGUQZ"
      }
    }
  ]
}